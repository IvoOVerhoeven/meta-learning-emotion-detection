{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05807788318072d650ff7d3f12118168354b5d5c1b01788c0f8c7e03b8ca64544",
   "display_name": "Python 3.8.8 64-bit ('acts': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Pre-processing and dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source download: https://drive.google.com/file/d/1y7yjshepNRPhnh-Qz5MTRbnopGn7KzUm/view?usp=sharing\n",
    "# Originally from: https://github.com/sarnthil/unify-emotion-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.unified_emotion import unified_emotion\n",
    "\n",
    "unified = unified_emotion(\"./data/datasets/unified-dataset.jsonl\")\n",
    "\n",
    "unified.prep()\n",
    "#unified.prep(text_tokenizer=manual_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'grounded_emotions': 2585,\n",
       " 'crowdflower': 40000,\n",
       " 'dailydialog': 102979,\n",
       " 'tales-emotion': 14771,\n",
       " 'tec': 21051,\n",
       " 'emoint': 7102}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "unified.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "grounded_emotions\n",
      "['@NBCNewYork WTF?? SERIOUSLY?!?!', '@assforDLS na my niggas @BlizzardStorm27  and @Smoke_EvryDay got me beat']\n",
      "\n",
      "crowdflower\n",
      "[\"@Puddynface2 Don't know yet  Lemme know if you come up with something though.\", \"Wee laddie's been SO upset for about 2 hours. Tried soothing him in bed, nursing, etc. Nope. Up at 3:30am for real food. Blue Clues now.\", '@themanwhofell compliment taken. Thanks. Key is to be yourself', \"gosh it's anoher cloudy day  wish they would go away.. or rain..\", '@turhangross Wow! Some person u are!', \"TIRED! goodnight twitter  its mother's day  happy mother's day  lov my moomy &lt;3 yayy! God Bless.\", \"@Zaraa_x ah that's annoying\", '#todo Cleaning the Apartment - again - who keeps making this mess? oh yeah .. me. $10 + hug for the person to help come clean']\n",
      "\n",
      "dailydialog\n",
      "[\"Everything seems to be getting worse . I don't know what to do with it .\", 'I hope so . And I will definitely tell you if I can not .', \"sounds good , and I don't have to queue up at the cashier .\", 'Yes , but I bet $ 200 dollars on the Cougars !', 'Recliner ? In my beautifully decorated living room ? I don Ã¢\\x80\\x99 t think so !', 'Whatever am i going to tell me parents .', \"Of course not . I'm afraid of them .\"]\n",
      "\n",
      "tales-emotion\n",
      "['And this is a warning to us, to be careful how we act, for we may some day find ourselves in the rag-bag, to be turned into white paper, on which our whole history may be written, even its most secret actions.', 'Poor child! there, go now.\"', 'Then they began to run, rushed into the parlour, and threw themselves round their father\"s neck.', '\"The best thing,\" thought Ib; \"the very best thing for me,- and found in the earth!', 'My wife will be anxious!\"', 'When she went into the kitchen to her work, and began to rake the ashes, the cook said, \"Let that alone till the morning, and heat the king\"s soup; I should like to run up now and give a peep: but take care you don\"t let a hair fall into it, or you will run a chance of never eating again.\"', 'At last they both lost themselves in the thicket; Christina began to cry, and then Ib cried too; and, after weeping and lamenting for some time, they stretched themselves down on the dry leaves and fell asleep.']\n",
      "\n",
      "tec\n",
      "[\"Off to mother in law's 70 birthday. Shush... it's a\", \"I think I'm getting a blister on my thumb from hobby whittling\", '@Yupits_Rohit well no test tomorrow its Sunday but I have to submit a paper online&amp; 2 more for Monday I really dont have enough time', 'Eurgh. ! So disgusting a guy found a dead decomposed bird in a salad bought from  ! OML. !!!!!', 'Infiltration in our lives. The illusion of so we accept their political Solutions. Tyranny', '@TomSeabrook93 fuck old school they shouldnt even be allowed on tv!']\n",
      "\n",
      "emoint\n",
      "[\"Aidy: *has a physics question*\\\\nAidy: '... ok, I'm not gonna ask Tristan cause I don't wanna aggravate her'\", 'Idk why but this Time around its so hard that it hurts, I already miss them all so much #silly #family #friends #nervous', \"Catering channel's at the height technics hearty enjoyment symptomatize: vrlfEyrN\", 'Love is when all your happiness and all your sadness and all your feelings are dependent on another person.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in unified.lens.keys():\n",
    "    trainloader, testloader = unified.get_dataloader(k, k=1)\n",
    "    _, text = next(trainloader)\n",
    "    print(k)\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " tensor([[  101, 19387,  1030, 23647,  6873, 26677, 10288,  2319,  1024,  1030,\n",
       "          10819, 18098,  6610, 26876,  1030,  8962,  2271,  1030, 11271, 22083,\n",
       "          16257, 10695,  1030,  4702, 16558, 19253, 10262,  2017,  1005,  2128,\n",
       "           2006,  8398,  2015,  2572, 11283,  2078,  2933,  1029,  2129,  2079,\n",
       "           2017,  4682,  1004, 23713,  1025,  3637,  2012,  2305,  1029,  1029,\n",
       "           1029,   102],\n",
       "         [  101, 19387,  1030,  8902,  5302, 18752, 16150, 18891,  2015,  1024,\n",
       "           1045,  2106,  7773,  2197,  5353,  1004, 23713,  1025,  2057,  1005,\n",
       "           2128,  7079,  2676,  1003,  2164,  4171,  2006,  2026,  3394,  2510,\n",
       "           3477,  1012,  1030,  2613,  5280, 19058, 24456,  2361,  2081,  1002,\n",
       "           5018,  2213,  1004, 23713,  1025,  2006,  2721, 29649,   102,     0,\n",
       "              0,     0],\n",
       "         [  101,  2317,  2160, 26536, 17125,  2740,  2729,  1010,  7318,  2696,\n",
       "           2361,  4366,  1011, 13229, 16770,  1024,  1013,  1013,  1056,  1012,\n",
       "           2522,  1013,  1046,  2078,  2615, 24759, 14536,  2620,  2571,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  1030, 22822,  2078, 17622,  1030,  2613,  5280, 19058, 24456,\n",
       "           2361,  3383,  1999,  1996,  2279,  2792,  1997,  1030,  8040, 10265,\n",
       "           2102,  1998,  1030,  3881,  8237,  2854,  5974,  2071,  4521,  2019,\n",
       "           1098, 29668, 29647,  1067,   999,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2123,  2102,  2022,  9981,  1997,  2026, 22132, 11239,  1001,\n",
       "          21766,  4502, 28426,  7265, 17643,  3401,  1001, 25992,  1001, 28480,\n",
       "           1001,  3407,  1001, 10148,  8649,  1001,  5343,  2050, 29649, 16770,\n",
       "           1024,  1013,  1013,  1056,  1012,  2522,  1013,  1060,  2078,  2615,\n",
       "           2615, 24703,  2575,  2361,  2683,  2549,   102,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  1030,  2016,  2860,  6806, 22994,  2229,  2066,  1996,  1001,\n",
       "          13157,  1997,  1059,  2860,  2475,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2004,  6728,  3695,  3593, 26641,  2015,  4125,  1010,  2610,\n",
       "           3738,  2468, 17220,  2015,  1010,  7435,  1998,  2591,  3667,  1011,\n",
       "           1996,  2899,  2695, 16770,  1024,  1013,  1013,  1056,  1012,  2522,\n",
       "           1013,  1020,  2361,  2683,  2546,  9103,  5339,  2213,  2243,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0],\n",
       "         [  101,  2973,  2048,  2367,  3268,  1012,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "trainloader, testloader = unified.get_dataloader('grounded_emotions', tokenizer=tokenizer, shuffle=True)\n",
    "next(trainloader)"
   ]
  },
  {
   "source": [
    "Sample a dataset using the square-root of their size as a probabilistic weight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'crowdflower'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from data.utils.sampling import dataset_sampler\n",
    "\n",
    "source_name = dataset_sampler(unified, sampling_method='sqrt')\n",
    "source_name"
   ]
  },
  {
   "source": [
    "Raises StopIteration when there is not enough data left to generate an N x K shot\n",
    "Done to avoid overfit in small datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "StopIteration",
     "evalue": "Some classes ran out of data.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1cb4a5ce86d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\data\\utils\\data_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Some classes ran out of data.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: Some classes ran out of data."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    next(testloader)"
   ]
  },
  {
   "source": [
    "# Custom Tokenizer\n",
    "Here we define some rules for manually cleaning the imported data.\n",
    "Given this is all internet sourced, it's strongly recommended to define something at least.\n",
    "Current manual tokenizer will:\n",
    "- Correct the text encodings\n",
    "- Align contractions with BERT tokenizers\n",
    "- Handles emojis (using emoji package) and twitter handles\n",
    "- Deals with some edge cases where Spacy's tokenizer fails"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "from data.unified_emotion import unified_emotion\n",
    "from data.utils.tokenizer import manual_tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified = unified_emotion(\"./data/datasets/unified-dataset.jsonl\")\n",
    "\n",
    "unified.prep()"
   ]
  },
  {
   "source": [
    "The raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['RT, follow @unitednude and WIN one of the 5 special collector items that we are giving away to our Twitter friends! #RT #WIN',\n",
       " 'I only started listening to prince this afternoon, but as a new fan its been a pretty great day.',\n",
       " 'Damn I get in my car n I got a full tank!!!',\n",
       " 'WEEKEND! En het beloofd een goeie te worden',\n",
       " '@DWKM The mechanic was going to let me take it away... but then he returned, broken brake in hand.',\n",
       " 'Also, someone took down the Swanson Pyramid of Greatness that was in the lab.',\n",
       " \"Due giorni fa c'era paul mccartney qui a milano e io non sono potuta andarlo a vedere\",\n",
       " 'work,work,work,work, fucking job',\n",
       " '@MisterJayEllBee I bet! Yeah not bad thanks, just about to do the daily commute',\n",
       " 'Family time tomorrow...',\n",
       " 'Creo q despues de 8 hras corridas leyendo/memorizando shit lo unico q entiendo es blahblahblah... On to la sentencia sumaria then',\n",
       " 'One of the nicest things about not working at the library anymore',\n",
       " 'The 9',\n",
       " 'That feeling when you know your slackin hard body on a shorty..',\n",
       " 'Some ppl makes ma mood turn into pure by just the sight of em.',\n",
       " \"yo i really cant stop laughing lol i never had micro's before those shits are to me i like my edges too much to get those braids\",\n",
       " 'Never let the of striking out get in your way.&#xA;--Babe Ruth',\n",
       " \"Just watched &quot;Single White Female.&quot; It's the  reason the only roommate I've ever had was my sister...and of course my husband.\",\n",
       " \"I think I'm scared of what of the future holds, I was wishin for some things and now I'm use to those.\",\n",
       " 'voted &quot;yes&quot; on maintaining current gun laws',\n",
       " 'Would love to kick a certain person in the face,',\n",
       " \"Can't wait for my Everlast pink heavy bag\",\n",
       " 'is built from disconnection fron the Source who provides peace',\n",
       " \"@WomanUnveiled I just hate it!!!!! why does she care if i'm late?!?!? aaaaaaaaaaaaa\"]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "trainloader, testloader = unified.get_dataloader('tec', shuffle=True)\n",
    "labels, text = next(trainloader)\n",
    "text"
   ]
  },
  {
   "source": [
    "The same, but now manually tokenized, sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['rt , follow @USER and win one of the 5 special collector items that we are giving away to our twitter friends ! # rt # win',\n",
       " 'i only started listening to prince this afternoon , but as a new fan its been a pretty great day .',\n",
       " 'damn i get in my car n i got a full tank ! ! !',\n",
       " 'weekend ! en het beloofd een goeie te worden',\n",
       " '@USER the mechanic was going to let me take it away ... but then he returned , broken brake in hand .',\n",
       " 'also , someone took down the swanson pyramid of greatness that was in the lab .',\n",
       " \"due giorni fa c ' era paul mccartney qui a milano e io non sono potuta andarlo a vedere\",\n",
       " 'work , work , work , work , fucking job',\n",
       " '@USER i bet ! yeah not bad thanks , just about to do the daily commute',\n",
       " 'family time tomorrow ...',\n",
       " 'creo q despues de 8 hras corridas leyendo / memorizando shit lo unico q entiendo es blahblahblah ... on to la sentencia sumaria then',\n",
       " 'one of the nicest things about not working at the library anymore',\n",
       " 'the 9',\n",
       " 'that feeling when you know your slackin hard body on a shorty ..',\n",
       " 'some ppl makes ma mood turn into pure by just the sight of them .',\n",
       " 'yo i really can not stop laughing lol i never had micro s before those shits are to me i like my edges too much to get those braids',\n",
       " 'never let the of striking out get in your way .&# xa ;-- babe ruth',\n",
       " 'just watched single white female . it s the reason the only roommate i have ever had was my sister ... and of course my husband .',\n",
       " 'i think i am scared of what of the future holds , i was wishin for some things and now i am use to those .',\n",
       " 'voted yes on maintaining current gun laws',\n",
       " 'would love to kick a certain person in the face ,',\n",
       " 'can not wait for my everlast pink heavy bag',\n",
       " 'is built from disconnection fron the source who provides peace',\n",
       " '@USER i just hate it ! ! ! ! ! why does she care if i am late ? ! ? ! ? aaaaaaaaaaaaa']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "list(map(manual_tokenizer, text))"
   ]
  },
  {
   "source": [
    "Can be easily slotted into the data loading process\n",
    "Does quite a lot longer though..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n"
     ]
    }
   ],
   "source": [
    "# Use below if you additionally want to limit sentences to those that overlap well with BERT\n",
    "# Not recommended for initial training \n",
    "#unified.prep(text_tokenizer=manual_tokenizer, text_tokenizer_kwargs={'bert_vocab': tokenizer.vocab.keys(), 'OOV_cutoff' :0.5, 'verbose':True})\n",
    "\n",
    "unified.prep(text_tokenizer=manual_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "grounded_emotions\n",
      "['rt @USER : .@USER that s true , but luckily @USER stayed locked in like a laser on it ! other journalists are dedicated to # trum ...', 'rt @USER : wow . last hour news :- rus agents charged in yahoo hack - comey to testify on rus - sessions refutes wiretap claim - ryan shif ...', 'rt @USER : and who could forget \" no pipelines without us steel , \" \" insurance for everybody \" \" i will be too busy for vacations gol ...', '@USER so sweet', 'rt @USER : thank you @USER ! i believe we can do this . HTTPURL HTTPURL', '# share your # happyhour # hotspot !']\n",
      "\n",
      "crowdflower\n",
      "['@USER mayyyybe', 'HTTPURL : domain umzug und neues design HTTPURL ...', '@USER should not you know your national holidays ?', 'sitting watching britain s got f all talent , but have watched a small girl cry and it s sad', 'is tired of summer already', 'last day working for tend', 'wondering why i am awake at 7am , writing a new song , plotting my evil secret plots muahahaha ... oh damn it , not secret anymore', 'shattered ! pwg botched his hybrid dolphin shirt order and sent him xl', '@USER me to mi sausage', '@USER i wud do but i m at work srry xx', '@USER biglots by my house has jesus virgin mary rings in one of those machines i rocked one for a while til that shit broke', '@USER i know . i want it to come bec i am excited , but then i do not bec it s going to go by so fast then it will be over', 'dammit . i need new cupcake tins', '@USER it s called retro my dear and i wear fifties fashion sometimes .... did you not see my birthday pictures ?', '@USER you are not singing in the rain ?', 'sitting here with my baby .. libby has a fever 101 . 0 she s fussy', 'happy mothers day mumm xoxo', '@USER thank you mama !', '@USER @USER someone is ignoring me being mean ..', 'working but it s fridaaaayyyyy', '@USER good luck ! if i remember right , everything in england is a rip off , anyway ! and next time , write me back ! haha', 'not going to lie , i am going to miss high school lunches . a lot . damn .', 'mikey i am bored', '@USER hiya , how s your week been ? ? just tried to dm you but your not following ! x']\n",
      "\n",
      "dailydialog\n",
      "['i m not crazy about it at all .', 'it s no use complaining . if we had got enough money , we would not put up with it !', 'i am really tired of my job in the bank . i am thinking about changing it .', 'i just felt embarrassed if i refused to drink when people toasted to me . but if i keep gulping down one cup after another , i am afraid i would feel unfit or sick .', 'i have got a sore throat and my chest hurts .', 'i have been thinking of taking i have been thinking of taking a crazy english course . do you think it s a good idea', 'great .', 'then i will send it by air , thank you .', 'good luck with that !', 'no , mine !', 'with everything , with everybody , with all this !', 'what a terrible house !', 'i can t believe it ! i thought the cougars were going to win for sure .', 'are you kidding ?', 'that s my uncle . you are my cousin ! hi cousin !', 'i knew there would be a catch !', 'i feel confused about the grammars .', 'oh , my god ! my wallet is lost . what should i do ? it drives me bonkers .', 'some people are wildly shooting on the next street . we must leave here as soon as possible !', 'what ? a fire ? oh , my god ! what shall i do ? please get me out of here !', 'i use those sites . hey ! let us go check out a flea market later .']\n",
      "\n",
      "tales-emotion\n",
      "['he had bead eyes , and his helmet was sewed on with stitches .', 'it was not so , however ; there was a being standing before his bed , and looking like the ghost of his deceased wife .', 'such a storm we have never witnessed in our day ; for that only happened in grandpapa s time , when he was quite a little boy .', 'what a nasty person ! \" said peter .', 'it is a horrible story : i will not keep it to myself , but let it go farther . \"', '\" shuh ! shuh ! little dirty feet ! \" said mrs . tittlemouse , clattering her dustpan .', 'when the twelve princesses heard this they laughed heartily ; and the eldest said , \" this fellow too might have done a wiser thing than lose his life in this way ! \"', '\" i never imagined anything like this , \" said the paper , \" when i was only a little blue flower , growing in the fields .', 'but i have not the jewel ; not that i cry about that - no , i must go higher up , into splendor and joy !', 'a third time he called out , \" god be with you , \" and then thinking he should like to know the cause of dispute between the three men , he went out and asked them why they were fighting so angrily with one another .', 'i exclaimed , \" and what wonders you can relate ? \"', 'a great big enormous trout came up - ker - pflop - p - p - p ! with a splash -- and it seized mr . jeremy with a snap , \" ow !', 'the hens , chicks , and even the cock sought shelter ; the wind tore down the planks between the two yards with a crash ; the tiles came tumbling down , but the weather - cock sat firm .', 'the guest , however , thought no otherwise than that he was to give up one of his ears , and ran as if fire were burning under him , in order to take them both with him .', '\" oh !', '\" i set it on my head and it kicked my face . \"', 'and the otters had cleared off all the frogs while he was asleep in winter --\" i have not had a good square meal for a fort - night , i am living on pig - nuts .', 'now will i pronounce thy sentence .', 'at last a very little girl came out of one of the wretched - looking houses , and ib asked her to tell him the way to the street he wanted ; she looked up timidly at him , and began to cry bitterly .', 'the poor lark was most unhappy as a prisoner in a cage .', '\" oh , dear , \" sighed little claus from the top of the shed , as he saw all the good things disappear .']\n",
      "\n",
      "tec\n",
      "['mau searching birthday cake buat simon aaahhh cake', '@USER omg i just got so scared ; the scene when the squirrel jumps out of the tree this movie is hysterical', 'after watching the new the thing i can not get the original s music out of my head . lubbly ! ( new film ok , not as good as original )', 'watching x factor now , can not believe @USER went home , such a talented girl ! !', 'far too long to expect us fans to wait - a whole year ? # depressed # bullimiamoment', 'ahh god damn it watched youtube videos with data on i thought i had wireless on major fail there goes my data for the month', 'a lovely 6 . 30am start tomorrow !', 'i feel awful , and it s way too freaking early . now off to leadership highschool ...', 'white chocolate buttons are heaven', '@USER i d say first haha , cause your real and most beautiful girls these days are fake as fuck', 'is not it shameful to be using vulgar language steeped in under the belt flirt tactics / humor once you breach the age of 25 ?', 'my nephew iz a lil nasty wat kids lick bottom of shoes', 'worried that i have done somethg grievous to offend my trainer considering the sadistic training prog he has just done me !', 'is an emotion that s overrated is an emotion that s out of control bt i like fear , fear keeps you sharp # realshit', 'people what they do not understand . but i understand fear .- copyrights k . ford', 'really not liking myself right now ! i hate fucking up . fuck !', 'u2 on the radio ! ! ! reminds of when @USER and i went the wrong fucking day to their concert -____- haha ! # idiots', 'after many tweets lindsay lohan still does not follow me on twitter ........ what a stupid bitch .']\n",
      "\n",
      "emoint\n",
      "['forever angry that gh ruined molly and morgan s bond / friendship', '@USER my heart because you left me for so long again \\\\ n \\\\ n * slight pout but it turned to a smile *\\\\ n \\\\ nheheh just kidding , no i am fine -', 'i can not have a dog in my flat ! literally no reason either ! sorry potential doggie ! # landlords # doglover # sad # angry # rescuedog # dog ;_;', 'how i murdered your mother # spookytv # horror', 'my boyfriend once forcibly stopped all of my anxiety coping methods at once ( holding me , forcing my hands down that kinda stuff ) and i -', 'body is sleepy but the mind is active . so sad ... have to get ready for work in 30 minutes . damn ! # restless', '@USER good morning , love ! happy first day of fall . let us make some awesome # autumnmemories # annabailey # laughter # smile', '[ moment of levity on the b41 ] baby : i want isis ! give me isis !\\\\ nmom : shh !\\\\ nbaby : i want isis !\\\\ nwest indian woman : she wants what ?\\\\ nmom : * ices * .', 'every single problem we ever face can be solved with a nice blend patience and optimism', 'the fact i have not had to wear a bra for a week and knowing i will have to start wearing one again after tomorrow is depressing :face_with_rolling_eyes: :face_with_rolling_eyes:', '@USER paddy mcnair is our joint top scorer ...... yeah ..... justlet that sink in haha', '\" my friend do you fly away now ? to a world that abhors you and i ? all that awaits you is a somber morrow no matter where the winds may blow \"']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in unified.lens.keys():\n",
    "    trainloader, testloader = unified.get_dataloader(k, k=3)\n",
    "    _, text = next(trainloader)\n",
    "    print(k)\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}