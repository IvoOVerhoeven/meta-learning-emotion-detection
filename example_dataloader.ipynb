{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0bb4eeb75ccadf76febac99b0fdc8506c0ed486862ccfc2dd7f417981edae5b2d",
   "display_name": "Python 3.7.10 64-bit ('cdm': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TODO\n",
    "## Unified Emotion\n",
    "- Remove samples with no-emotion class\n",
    "- Convert multiple labels to multiple examples with different labels\n",
    "- Come up with better assignment scheme for train/valid/test splits\n",
    "- Drop \"#SemST\" from ssec sentences\n",
    "\n",
    "## Go Emotions\n",
    "- Get rid of print when loading (low priority)\n",
    "- Include cases for manual tokenizer\n",
    "- Convert multiple labels to multiple examples with different labels (check with Luuk)\n",
    "\n",
    "## Manual Tokenizer\n",
    "- check if works for go emotion\n",
    "- incorporate special tokens into huggingface tokenizer\n",
    "\n",
    "## Dataloaders\n",
    "- loop Stratifiedloader for infinite sampling\n",
    "- Rewrite train script to use correct dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data.utils.data_loader import StratifiedLoader, AdaptiveNKShotLoader"
   ]
  },
  {
   "source": [
    "# Datasets\n",
    "## Unified Emotion\n",
    "\n",
    "Data source download: https://drive.google.com/file/d/1y7yjshepNRPhnh-Qz5MTRbnopGn7KzUm/view?usp=sharing\n",
    "Originally from: https://github.com/sarnthil/unify-emotion-datasets\n",
    "\n",
    "\n",
    "Klinger, R. & Bostan, L. (2018, August). An analysis of annotated corpora for emotion classification in text. In Proceedings of the 27th International Conference on Computational Linguistics (pp. 2104-2119)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonlines'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e7d097bd7a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munified_emotion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munified_emotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munified_emotion_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munified_emotion_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ATCS/meta-learning-emotion-detection/data/unified_emotion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjsonlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jsonlines'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data.unified_emotion import unified_emotion, unified_emotion_info\n",
    "\n",
    "pd.DataFrame(unified_emotion_info())"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'unified_emotion' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d0b885ec0f7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m unified = unified_emotion(\"./data/datasets/unified-dataset.jsonl\",\\\n\u001b[0m\u001b[1;32m      2\u001b[0m     include=['crowdflower', 'dailydialog', 'electoraltweets', 'emoint', 'emotion-cause', 'grounded_emotions', 'ssec', 'tec'])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0munified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unified_emotion' is not defined"
     ]
    }
   ],
   "source": [
    "unified = unified_emotion(\"./data/datasets/unified-dataset.jsonl\",\\\n",
    "    include=['crowdflower', 'dailydialog', 'electoraltweets', 'emoint', 'emotion-cause', 'grounded_emotions', 'ssec', 'tec'])\n",
    "\n",
    "unified.prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'grounded_emotions': 2585,\n",
       " 'ssec': 4868,\n",
       " 'crowdflower': 40000,\n",
       " 'dailydialog': 102979,\n",
       " 'emotion-cause': 2414,\n",
       " 'tec': 21051,\n",
       " 'emoint': 7102,\n",
       " 'electoraltweets': 4056}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "unified.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "grounded_emotions\n",
      "1 @realDonaldTrump @POTUS @IvankaTrump Mental health benefits removed from trumpcare. #trumpcare https://t.co/pE5a3YFh7Z\n",
      "0 RT @Tackspayer: @IorettaIynch @HITEXECUTIVE I'd prefer an unemployed Constitutional scholar, Barack Obama. The karma would be deliciously sâ¦\n",
      "\n",
      "ssec\n",
      "0 @brandileighhhhh its called sexual coercion, and it is the same as rape. #RapeCulture #SemST\n",
      "2 #Northwest #HeatWave continues. First time. Ever. My tomato plants have fruit. In JUNE! #Oregon #Organic #SemST\n",
      "3 Make sure to make it to the Brew House in Pella, IA tomorrow @ 3 to meet with @HillaryClinton supporters! #SemST\n",
      "1 The guy in the multicolored shirt looks chi as fuck. #SemST\n",
      "6 We are what we are. Nothing more, nothing less. #spirituality #SemST\n",
      "4 Pretend I'm a #tree and #save me. -babies everywhereyouthgen #SemST\n",
      "5 Serious question for my atheist libertarians: How can rights exist without God? #ChristianLibertarian #SemST\n",
      "\n",
      "crowdflower\n",
      "5 @jeffparks Good morning, sir\n",
      "6 Fell down the stairs at dancing, sword fell on me and now my bum hurts\n",
      "3 Happy Monday!  Lots of little things to do today!  Tried to water plants out front very early in jammies! Got caught by two neighbors!!\n",
      "2 And I wanted us to leave at 12:45 to do a 1 p.m. showing (staff retreat mini)\n",
      "7 @MusicLover_15 No, I haven't seen it yet!  But once it comes out on DVD.. ;) hehe. Haha\n",
      "4 Seeing lots of my FB friends are friending or becoming fans of Zoozoo (Voda's new face after the pug). Even iLike\n",
      "0 @trvsbrkr it's not working here\n",
      "1 Have I mentioned this bus was sloooow? on it for about one hour now\n",
      "\n",
      "dailydialog\n",
      "1 I must admit I'm not at all interested in math .\n",
      "4 Why don â t you find the information on the internet instead ?\n",
      "3 Good . I am here visiting my girlfriend . I want her to have a good time .\n",
      "0 Oh , you men ! You are all the same .\n",
      "6 Seriously ? But you are such a genius .\n",
      "5 I am sorry , sir . You bought it 2 weeks ago , and you can only refund it in one week .\n",
      "2 I'm afraid you are beginning to look a little overweight . You really need to stop smoking . That's the main reason you're unhealthy .\n",
      "\n",
      "emotion-cause\n",
      "3 He felt both elated and frightened . \n",
      "4 He stood there stoically , hiding his grief as Newlands announced he had received only twelve votes . \n",
      "5 She just looked up at him with bewildered eyes and he put her firmly away , turning to launch himself into the water . \n",
      "1 The horse , having been abandoned in the traces for twenty-four hours , was utterly disgruntled . \n",
      "0 Busking or playing musical instruments in the Underground , to the annoyance of other passengers , is an offence \n",
      "2 Also some disquiet surrounds the production of \" second generation \" vaccines using genetically engineered microbes to make fragments of viruses . \n",
      "\n",
      "tec\n",
      "5 @xkusayca ik heb ook miss 5 pakken chocola thuis en 2kg pepernoten maar ik mag er nieet aan zitten xD -.-\n",
      "4 what time is it???  time?? LOOL no, not a chance\n",
      "3 @Andrea_Malik sehh\n",
      "1 The conversation that @JDougherty82 and I are having on  is simply EPIC.\n",
      "2 â@RevRunWisdom not afraid of tomorrow, for I have seen yesterday and I love today #lessâ\n",
      "0 If u smack ur lips while u eat in my vicinity best believe I'll rip your face off and wear it to church.\n",
      "\n",
      "emoint\n",
      "0 ... flat party and I instantly get bollocked about it. #fuming\n",
      "1 The anxiety I have right nowð­ð­ð­\n",
      "2 @enews #breezy deserve it..\n",
      "3 @HutchinsonDave I don't know whether to despair or agitate for a cull.\n",
      "\n",
      "electoraltweets\n",
      "3 @davidjeremiah Barack Obama is a demon bent on destruction but Romney is too. Mormonism is the apostasy church that recreates Christ.\n",
      "0 @Norsu2 @IngrahamAngle Yes, Laura, you need more information about the man. Please do us all the favor. #tcot #mitt2012 #romney\n",
      "1 Feels like yesterday I was here in Concord, NH w/ @JoeBiden to sign official candidacy paperwork in Oct 2011 #VPinNH #4moreyears\n",
      "9 #GOP2012 I love @MichelleObama great speech tonight!! #DNC\n",
      "2 Dear #GOP Please think long &amp hard over the next 4 years, evaluate your direction &amp select an appropriate candidate for President in '16 #fb\n",
      "5 Glad we will be in center for @dnc. We have fought rain all week, we will welcome @BarackObama like there is 60k in the house!#Election2012\n",
      "8 My god the sheer number of people that drink the Kool Aid of the #GoP and #Democrats and think that they are different flavors is astounding\n",
      "4 #MyHomelessSignWouldSay VOTE FOR OBAMA OR BE PREPARED TO SEE ALOT MORE SIGNS LIKE THIS!!!\n",
      "7 I think Romney will bring us middle class blatantly down to the gutters but I feel like Obama is secretly up to no good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in unified.lens.keys():\n",
    "    dataset = unified.datasets[k]['train']\n",
    "    trainloader = StratifiedLoader(dataset=dataset, device=torch.device('cpu'), k=1)\n",
    "    labels, text, _, _ = next(trainloader)\n",
    "    print(k)\n",
    "    for lab, sent in zip(labels, text):\n",
    "        print(lab, sent)\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## GoEmotion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No config specified, defaulting to: go_emotions/simplified\n",
      "Reusing dataset go_emotions (/Users/xinyichen/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/b781b3f96f1b333b895ded30861c0d4a07d66e1cfbdfb89bc3fb4d5fc899aa27)\n",
      "100%|██████████| 44/44 [00:01<00:00, 33.45ba/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 37.42ba/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 38.08ba/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'go_emotions': 36491}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from data.go_emotions import go_emotions\n",
    "\n",
    "go_emotion = go_emotions(first_label_only=True)\n",
    "go_emotion.prep()\n",
    "\n",
    "go_emotion.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No config specified, defaulting to: go_emotions/simplified\n",
      "Reusing dataset go_emotions (/Users/xinyichen/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/b781b3f96f1b333b895ded30861c0d4a07d66e1cfbdfb89bc3fb4d5fc899aa27)\n",
      "100%|██████████| 44/44 [00:01<00:00, 33.03ba/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 37.16ba/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 32.19ba/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data as data\n",
    "\n",
    "dataset = go_emotions(first_label_only=True)\n",
    "dataset.prep()\n",
    "# dataset.lens\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "len(dataset['go_emotions']['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'MetaStratifiedLoader' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6c04407d4cd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'go_emotions'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ATCS/meta-learning-emotion-detection/data/go_emotions.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, source_name, k, tokenizer, shuffle)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0msource_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             dataloader = MetaStratifiedLoader(source_dict=source_dict,\n\u001b[0m\u001b[1;32m    131\u001b[0m                                               \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                               \u001b[0mclass_to_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MetaStratifiedLoader' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = dataset.get_dataloader('go_emotions', k=8,tokenizer=tokenizer, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# use normal data loader\n",
    "#need to apply tokenizer to text\n",
    "train_loader = data.DataLoader(dataset['go_emotions']['train'], batch_size=4,shuffle=False , num_workers=4)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-d9367ce734e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'go_emotions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cdm/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2269\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2271\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2272\u001b[0m             )\n\u001b[1;32m   2273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cdm/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2454\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m         )\n\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cdm/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# we add an overflow_to_sample_mapping array (see below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0msanitized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_and_encodings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tokenizer(dataset['go_emotions']['train']['text'],return_tensors='pt',padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go_emotions\n2 I've said it before, but yuck, kissing that bloody mouth... Watch out, [NAME], you don't know where that's been.\n14 Yeah but you're not anymore I'm afraid.\n3 Yeah I've noticed that. I probably give off Aspie traits to NTs but Aspie like traits bug me\n26 Wow the [NAME] replies appeared in less than ten minutes this time!\n15 Haaaaa this was just on OZ the other night. Thanks.\n8 I need help with corsets but otherwise would be mortified to need help for every day clothes.\n0 That would be cool too!\n6 Maybe it’s just too early but I can’t figure out what that’s supposed to be.\n1 So we need a jewelry store and a tv show. Bet lol\n5 Avoid. Without a contract he can kick you out at short notice any time And when you pay a deposit make sure it's protected.\n12 2. I hate to say it but it’s the same thing I do and I hate myself for it\n16 I don't see any shoes on his feet after he lands. Kid is fucking dead.\n17 Oh my goodness it's like a happy little cloud! What breed is it? Either way, omg enjoy petting that super soft puppy coat for me! \n25 Wasn't expecting these feels man. I'm so sorry for your loss!\n7 That glass woulda broken the truck ha\n10 I don’t want my tax dollars going to some psycho who thinks he’s a girl trapped in a mans body\n20 You are welcome, I have faced lot of sibling related issues. Hope things work out well for you.\n4 I agree. That is a fight better left for later.\n13 Thank you guys so much! IM FINALLY IN THE KNOW!\n9 I really need to stop taking my guns fishing with me. I keep losing them!!! :(\n24 I'm sorry for what happened to you. I guess you were sending mixed signals all the time.\n18 I love that logic \"I don't like it so it must not exist.\"\n22 Yeah I remember when they banned bathrooms, crazy thing. \n11 They’re disgusting people inside and out\n23 Dude was okay?! Oh thank god, i figured at best paralyzed from the waist down\n21 The intent is to provide the players with a sense of pride and accomplishment...\n19 I'm worried he's too small. I love his quickness, but sub-170 is scary for a guy that'll be running over the middle.\n\n"
     ]
    }
   ],
   "source": [
    "for k in go_emotion.lens.keys():\n",
    "    dataset = go_emotion.datasets[k]['train']\n",
    "    trainloader = StratifiedLoader(dataset=dataset, device=torch.device('cpu'), k=1)\n",
    "    labels, text, _, _ = next(trainloader)\n",
    "    print(k)\n",
    "    for lab, sent in zip(labels, text):\n",
    "        print(lab, sent)\n",
    "    print()\n"
   ]
  },
  {
   "source": [
    "# Custom Tokenizer\n",
    "Here we define some rules for manually cleaning the imported data.\n",
    "Given this is all internet sourced, it's strongly recommended to define something at least.\n",
    "Current manual tokenizer will:\n",
    "- Correct the text encodings\n",
    "- Align contractions with BERT tokenizers\n",
    "- Handles emojis (using emoji package) and twitter handles\n",
    "- Deals with some edge cases where Spacy's tokenizer fails"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-719bba6618af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanual_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from data.utils.tokenizer import manual_tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.additional_special_tokens = [\"HTTPURL\", \"@USER\"]"
   ]
  },
  {
   "source": [
    "The raw data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'unified' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4750a35a8629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grounded_emotions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unified' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = unified.datasets['grounded_emotions']['train']\n",
    "trainloader = StratifiedLoader(dataset=dataset, device=torch.device('cpu'), k=8)\n",
    "\n",
    "labels, text, _, _ = next(trainloader)\n",
    "text"
   ]
  },
  {
   "source": [
    "The same, but now manually tokenized, sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['i know you @USER HTTPURL',\n",
       " \"HTTPURL how many more ways can # 45 show us he doesn ' t give a fuck about america ( ns ) ! he s doing all he can to hurt us ! !\",\n",
       " 'rt @USER : andy : can not say it better than gump ... stupid is as stupid does ! these cuts are # pennywiseandpoundfoolish they will cost ...',\n",
       " '@USER he has no clue . like all the eo s .',\n",
       " 'rt @USER : photographer spencer amonwatvorakul talks about quitting his day job for his dream # standcreative2 HTTPURL ...',\n",
       " \"my # tmc 🇺 🇸 :smiling_face_with_sunglasses: , u have been on point :check_mark_button: :fire: !exemplary comebacks brilliant original content ! doesn ' t get any better than that !! getting caught up :smiling_face:  🇺 🇸 .\",\n",
       " 'rt @USER : # oklahoma authorities get shortey . # gop state senator , former # trump coordinator faces child prostitution charges . https :/ ...',\n",
       " 'rt @USER : @USER @USER @USER @USER they should take your medical license for violating your oath . \" first do n ...',\n",
       " 'that is truly sickening ! to quote @USER # bad # sad HTTPURL',\n",
       " '@USER really ? that s stunning . what to the doctors say ?',\n",
       " '@USER @USER you are making yourself look like an ass . way to end a good career . # liar',\n",
       " 'rt @USER : moldy church records in latin america document the lives of millions of slaves HTTPURL',\n",
       " 'are you beginning to see the pattern here as huntsman hits the moscow rich boys club ? HTTPURL',\n",
       " 'rt @USER : our new series discusses team branding , and @USER have had success in that area that surpasses most HTTPURL ...',\n",
       " '@USER @USER prettyyyy sky',\n",
       " 'emma looks great . she s smart , well educated , she s has the right 2 be whatever she wants to be . feminist great HTTPURL']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "list(map(manual_tokenizer, text))"
   ]
  },
  {
   "source": [
    "Can be easily slotted into the data loading process\n",
    "Does quite a lot longer though..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n",
      "Removed sentence for bad encoding.\n"
     ]
    }
   ],
   "source": [
    "# Use below if you additionally want to limit sentences to those that overlap well with BERT\n",
    "# Not recommended for initial training \n",
    "#unified.prep(text_tokenizer=manual_tokenizer, text_tokenizer_kwargs={'bert_vocab': tokenizer.vocab.keys(), 'OOV_cutoff' :0.5, 'verbose':True})\n",
    "\n",
    "unified.prep(text_tokenizer=manual_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Example data\n",
      "grounded_emotions\n",
      "sadness [CLS] @ user what regulations caused harm to remington? thank you. [SEP]\n",
      "joy [CLS] i am doing it!! @ user @ user # atmosphereplus # socool # nbavirginnomore # staplescenter... httpurl [SEP]\n",
      "\n",
      "ssec\n",
      "anger [CLS] ( it s just a night watcheasy to set up. staggered pickets ( google it ) work best ) # whoisburningblackchurches # semst [SEP]\n",
      "fear [CLS] rosalind peterson addressing un on how aerosol spraying ( chemtrails ) is affecting agriculture. # notadebate # geoengineering # semst [SEP]\n",
      "joy [CLS] coming from a female that was taken away the ability to have children. i still believe women should have the ability to choose. # semst [SEP]\n",
      "disgust [CLS] i don't buy a dress that i can not completely zip up and fasten on my own. # semst [SEP]\n",
      "trust [CLS] people who have been pregnant can be pro choice. people who can not have kids can be pro choice. people who have a uterus can be # semst [SEP]\n",
      "sadness [CLS] pretend i am a # tree and # save me. - babies everywhereyouthgen # semst [SEP]\n",
      "surprise [CLS] the # mntwins game is going really fast tonight. more proof of # semst [SEP]\n",
      "\n",
      "crowdflower\n",
      "noemo [CLS] rain!!!!!!!!!!!! aaaaaaaaaahhhhhhhh! i am going to melt. damn it s cold. freakin cold. brrrrrr [SEP]\n",
      "sadness [CLS] @ user why i ai not on ur # ff list? i m hurt [SEP]\n",
      "joy [CLS] i love the dreambears!.. i want a gay best friend! [SEP]\n",
      "fear [CLS] @ user you are still welcome - the door s wide enough for your zimmer frame [SEP]\n",
      "surprise [CLS] omg... did i just see a tweet from miss bonnie??? amazing... my phone died yesterday... and oster has alltel i miss you [SEP]\n",
      "love [CLS] watching chelsea lately! loveeeee her 3 [SEP]\n",
      "anger [CLS] i really ai not woth a f * ck. i can not do anythin right. what s wrong with me? [SEP]\n",
      "disgust [CLS] fml. forgot alli s dance recital is tonight. now i am stuck talking to munchkins all night instead of being at devon s bonfire. : / [SEP]\n",
      "\n",
      "dailydialog\n",
      "disgust [CLS] i get antsy not because you praise a guy, but because you may be taken for a ride by a guy like him. [SEP]\n",
      "noemo [CLS] i prefer summer, especially the summer evenings. when the sun comes down, it is so nice to take a walk and breathe. after a rain shower, the smell of the air is refreshing. it is also a best reason for ice - cream. [SEP]\n",
      "joy [CLS] it s time to go and i hope we can get together again soon. [SEP]\n",
      "anger [CLS] the heating controls don't work anymore, so it always feels like it s about 100 degrees in the car - even in the summer! [SEP]\n",
      "surprise [CLS] did you? and what did you study? [SEP]\n",
      "sadness [CLS] i d love to, but i am afraid i can not. [SEP]\n",
      "fear [CLS] but, dad, it s stormy outside. [SEP]\n",
      "\n",
      "emotion-cause\n",
      "joy [CLS] \" debbie would be pleased, \" she said. [SEP]\n",
      "sadness [CLS] then he relaxes into a sorrowful smile, like when you remember someone you loved who died a long time ago. [SEP]\n",
      "surprise [CLS] he looked quite nonplussed. [SEP]\n",
      "disgust [CLS] senator sherman had shot marginally less well than his son and was openly disgruntled about this. [SEP]\n",
      "anger [CLS] my hands dart indignantly about my desk as if they were offended mice, opening files, annotating minutes, picking up the receiver. [SEP]\n",
      "fear [CLS] he seemed agitated, restlessly pacing about, looking out into the crowds, then drawing back into the shelter of the arcade. [SEP]\n",
      "\n",
      "tec\n",
      "surprise [CLS] 48 hours and a few minutes until is over. forget what my upper lip looks like. [SEP]\n",
      "sadness [CLS] when you run out of the thing you want, and you are broke. [SEP]\n",
      "joy [CLS] let us stop beating around the bush [SEP]\n",
      "disgust [CLS] the conversation that @ user and i are having on is simply epic. [SEP]\n",
      "fear [CLS], updating my uefi bios tomorrow, first time the new one [SEP]\n",
      "anger [CLS] an enraged person only gets angrier when you say \" i completely understand. \" [SEP]\n",
      "\n",
      "emoint\n",
      "anger [CLS] lgbtq media should inform, inspire, entertain unite our community. it should not give platform 2 those whose goal is 2 offend us 4 attention [SEP]\n",
      "fear [CLS] @ user the irony is that those protesting about this kind of stuff are the orwellian nightmare they think they are fighting against. [SEP]\n",
      "joy [CLS] @ user no okay you don't not need to be going out of your way to make sure you are pleasing everyone do what makes you happy [SEP]\n",
      "sadness [CLS] a moment : \\ nif you kill it in the spirit, it will die in the natural!!!'- @ user # murder # suicide # depression # racism # pride [SEP]\n",
      "\n",
      "electoraltweets\n",
      "disgust [CLS] @ user the appropriate toy 4 romney is not an etch a sketch its silly putty. he will take on any form given to him by a misguided gop. [SEP]\n",
      "anger [CLS] will obama fire the person responsible for this statement?... misguided individuals to hurt the religious feelings of muslims [SEP]\n",
      "anticipation [CLS] i am going to start saying henry merritt paulson the third with the same disdain as the barack hussein obama people. [SEP]\n",
      "trust [CLS] really fantastic video - mitt romney and a gay vietnam vet talk over new hampshire s gay marriage policy # gayrights # election2012 [SEP]\n",
      "confusion [CLS] remember how i read romney / ryan slash why did i do that [SEP]\n",
      "joy [CLS] we toke care of business in 2008 now it s time to do the same in 2012!! # 4moreyears # obamaordie? obama accomplishments? [SEP]\n",
      "surprise [CLS] saw a headline on my phone that obama is leaning toward ryan s education plan... say what? what? me thinks i just saw a pig flyin [SEP]\n",
      "fear [CLS] neither dem nor rep - nor muslim - is reliable voice on jesus politics. mt @ user the # gop of today is the antithesis of # christ. [SEP]\n",
      "sadness [CLS] i think romney will bring us middle class blatantly down to the gutters but i feel like obama is secretly up to no good. [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nExample data')\n",
    "for k in unified.lens.keys():\n",
    "    dataset = unified.datasets[k]['train']\n",
    "    trainloader = StratifiedLoader(dataset=dataset, device=torch.device('cpu'), k=1)\n",
    "\n",
    "    labels, text, _, _ = next(trainloader)\n",
    "    print(k)\n",
    "\n",
    "    label_map = {v: k for k, v in unified.label_map[k].items()}\n",
    "    tokenized_texts = list(map(tokenizer.decode, tokenizer(text)['input_ids']))\n",
    "    for txt, label in zip(tokenized_texts, labels):\n",
    "        print(label_map[label], txt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go_emotion.prep(text_tokenizer=manual_tokenizer)"
   ]
  },
  {
   "source": [
    "# Sampling\n",
    "## Dataset sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dailydialog'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from data.utils.sampling import dataset_sampler\n",
    "\n",
    "source_name = dataset_sampler(unified, sampling_method='sqrt')\n",
    "source_name"
   ]
  },
  {
   "source": [
    "## Dataloaders\n",
    "Changed somewhat from last time. \n",
    "\n",
    "Now dataloaders must be generated manually using specific dataset (dict with labels as keys, lists of examples as values).\n",
    "\n",
    "Samples from data and returns **both** the support and query.\n",
    "\n",
    "Thus,\n",
    "\n",
    "IN: dataset\n",
    "\n",
    "OUT: support labels, support text, query labels, query text\n",
    "\n",
    "If Huggingface tokenizer is passed, text is full model input (attention masks, token types, etc.)\n",
    "\n",
    "Can be fed into model as,\n",
    "\n",
    "```\n",
    "model(**text)\n",
    "```\n",
    "\n",
    "### Stratified Sampling\n",
    "Traditional N-way k-shot, balanced across classes.\n",
    "\n",
    "Requires manually specifying k, which corresponds to batch size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from data.utils.data_loader import StratifiedLoader, AdaptiveNKShotLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'unified' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eb09b33d5a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ssec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msupport_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unified' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = unified.datasets['ssec']['train']\n",
    "trainloader = StratifiedLoader(dataset=dataset, device=torch.device('cpu'), k=16)\n",
    "support_labels, support_text, query_labels, query_text = next(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({0: 16, 2: 16, 3: 16, 1: 16, 6: 16, 4: 16, 5: 16})"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "Counter(support_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({0: 16, 2: 16, 3: 16, 1: 16, 6: 16, 4: 16, 5: 15})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "Counter(query_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "#    next(trainloader)"
   ]
  },
  {
   "source": [
    "### Adaptive N-way k-shot\n",
    "Dataloader with adaptive/stochastic N-way, k-shot batches.\n",
    "\n",
    "Support set has random number of examples per class, although proportional to class size.\n",
    "\n",
    "Query set is always balanced.\n",
    "\n",
    "Not all classes are present if more than 5 classes are present in the dataset.\n",
    "\n",
    "Algorithm taken from:\n",
    "\n",
    "    Triantafillou et al. (2019). Meta-dataset: A dataset of datasets for learning to learn from few examples. arXiv preprint arXiv:1903.03096.\n",
    "\n",
    "Steps are as follows:\n",
    "    \n",
    "1. Sample subset of classes (min 5, max all classes)\n",
    "    \n",
    "2. Define query set size (max 10 per class)\n",
    "    \n",
    "3. Define support set size (max 128 for all)\n",
    "    \n",
    "4. Fill support set with samples, stochastically proportional to support set size\n",
    "    \n",
    "5. Fill query set with remaining samples\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unified.datasets['ssec']['train']\n",
    "trainloader = AdaptiveNKShotLoader(dataset=dataset, device=torch.device('cpu'), max_support_size=128)\n",
    "support_labels, support_text, query_labels, query_text = next(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({4: 3, 6: 3, 0: 84, 5: 2, 3: 25, 2: 8})"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "Counter(support_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({4: 10, 6: 10, 0: 10, 5: 10, 3: 10, 2: 10})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "Counter(query_labels)"
   ]
  }
 ]
}