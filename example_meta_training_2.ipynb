{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd05807788318072d650ff7d3f12118168354b5d5c1b01788c0f8c7e03b8ca64544",
   "display_name": "Python 3.8.8 64-bit ('acts': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, get_constant_schedule_with_warmup\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from models.seqtransformer import SeqTransformer\n",
    "from data.unified_emotion_numpy import unified_emotion\n",
    "from data.utils.tokenizer import manual_tokenizer, specials\n",
    "from data.utils.data_loader_numpy import StratifiedLoader\n",
    "from data.utils.sampling import dataset_sampler\n",
    "from utils.metrics import logging_metrics\n",
    "\n",
    "config = {'encoder_name': 'bert-base-cased',\n",
    "'nu': 12,\n",
    "'hidden_dims': [512, 256],\n",
    "'act_fn': 'tanh',\n",
    "'include': ['grounded_emotions'],\n",
    "'max_support_size': 32,\n",
    "'n_inner': 5,\n",
    "'warmup_steps': 25,\n",
    "'max_episodes': 250,\n",
    "'meta_lr': 5e-5,\n",
    "'inner_lr': 1e-3,\n",
    "'output_lr': 1e-1,\n",
    "'checkpoint_path': 'ProtoMAML_Rebuild',\n",
    "'version': 'overfit_test',\n",
    "'gpu': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving models and logs to ProtoMAML_Rebuild\\overfit_test\n",
      "Train | Episode 0 | Task grounded_emotions   , N=2 | Loss 6.9240E-01, Acc  0.44, F1  0.42 | Mem  1.74 GB\n",
      "Train | Episode 1 | Task grounded_emotions   , N=2 | Loss 6.9322E-01, Acc  0.56, F1  0.56 | Mem  1.74 GB\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-db34ffe65092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mqueries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\models\\seqtransformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, model_input)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ivoon\\Documents\\GitHub\\meta-learning-emotion-detection\\modules\\encoders.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, model_input)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pooler_output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         )\n\u001b[1;32m--> 971\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    972\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    566\u001b[0m                 )\n\u001b[0;32m    567\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    569\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    457\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     ):\n\u001b[1;32m--> 387\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    388\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\acts\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Logging Directories #\n",
    "#######################\n",
    "log_dir = os.path.join(config['checkpoint_path'], config['version'])\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'tensorboard'), exist_ok=True)\n",
    "os.makedirs(os.path.join(log_dir, 'checkpoint'), exist_ok=True)\n",
    "print(f\"Saving models and logs to {log_dir}\")\n",
    "\n",
    "with open(os.path.join(log_dir, 'checkpoint', 'hparams.pickle'), 'wb') as file:\n",
    "    pickle.dump(config, file)\n",
    "\n",
    "## Initialization\n",
    "# Device\n",
    "device = torch.device('cuda' if (torch.cuda.is_available() and config['gpu']) else 'cpu')\n",
    "\n",
    "# Build the tensorboard writer\n",
    "writer = SummaryWriter(os.path.join(log_dir, 'tensorboard'))\n",
    "\n",
    "###################\n",
    "# Load in dataset #\n",
    "###################\n",
    "dataset = unified_emotion(\"./data/datasets/unified-dataset.jsonl\",\n",
    "                            include=config['include'])\n",
    "dataset.prep(text_tokenizer=manual_tokenizer)\n",
    "\n",
    "####################\n",
    "# Init models etc. #\n",
    "####################\n",
    "\n",
    "model_init = SeqTransformer(config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['encoder_name'])\n",
    "\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': specials()})\n",
    "model_init.encoder.model.resize_token_embeddings(len(tokenizer.vocab))\n",
    "\n",
    "meta_optimizer = optim.SGD(model_init.parameters(), lr=config['meta_lr'])\n",
    "meta_scheduler = get_constant_schedule_with_warmup(meta_optimizer, config['warmup_steps'])\n",
    "\n",
    "model_init = model_init.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#######################\n",
    "# Overfit query batch #\n",
    "#######################\n",
    "task = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "\n",
    "datasubset = dataset.datasets[task]['train']\n",
    "\n",
    "dataloader = StratifiedLoader(datasubset, k=16, shuffle=True, max_batch_size=config['max_support_size'], tokenizer=tokenizer, device=device, classes_subset=False)\n",
    "\n",
    "_, _, query_labels, query_input = next(dataloader)\n",
    "overfit_queries = [(query_labels, query_input)]\n",
    "\n",
    "for episode in range(config['max_episodes']):\n",
    "    queries = []\n",
    "    \n",
    "    #################\n",
    "    # Sample a task #\n",
    "    #################\n",
    "    task = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "\n",
    "    datasubset = dataset.datasets[task]['train']\n",
    "\n",
    "    dataloader = StratifiedLoader(datasubset, k=16, shuffle=True, max_batch_size=config['max_support_size'], tokenizer=tokenizer, device=device, classes_subset=False)\n",
    "\n",
    "\n",
    "    #####################\n",
    "    # Create model_task #\n",
    "    #####################\n",
    "\n",
    "    model_task = deepcopy(model_init)\n",
    "    model_task_optimizer = optim.SGD(model_task.parameters(), lr=config['inner_lr'])\n",
    "    model_task.train()\n",
    "    model_task.zero_grad()\n",
    "\n",
    "    #######################\n",
    "    # Generate prototypes #\n",
    "    #######################\n",
    "\n",
    "    support_labels, support_input, query_labels, query_input = next(dataloader)\n",
    "    queries.append((query_labels, query_input))\n",
    "\n",
    "    model_init.train()\n",
    "    \n",
    "    y = model_init(support_input)\n",
    "\n",
    "    labs = torch.sort(torch.unique(support_labels))[0]\n",
    "    prototypes = torch.stack([torch.mean(y[support_labels==c], dim=0) for c in labs])\n",
    "\n",
    "    W_init = 2 * prototypes\n",
    "    b_init = -torch.norm(prototypes, p=2, dim=1)\n",
    "\n",
    "    W_task, b_task = W_init.detach(), b_init.detach()\n",
    "    W_task.requires_grad, b_task.requires_grad = True, True\n",
    "\n",
    "    #################\n",
    "    # Adapt to data #\n",
    "    #################\n",
    "    for _ in range(config['n_inner']):\n",
    "    \n",
    "        support_labels, support_input, query_labels, query_input = next(dataloader)\n",
    "        queries.append((query_labels, query_input))\n",
    "\n",
    "        y = model_task(support_input)\n",
    "        logits = F.linear(y, W_task, b_task)\n",
    "\n",
    "        inner_loss = loss_fn(logits, support_labels)\n",
    "\n",
    "        W_task_grad, b_task_grad = torch.autograd.grad(inner_loss, [W_task, b_task], retain_graph=True)\n",
    "\n",
    "        inner_loss.backward()\n",
    "\n",
    "        model_task_optimizer.step()\n",
    "        W_task = W_task - 1e-1 * W_task_grad\n",
    "        b_task = b_task - 1e-1 * b_task_grad\n",
    "    \n",
    "\n",
    "    #########################\n",
    "    # Validate on query set #\n",
    "    #########################\n",
    "    for module in model_task.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.eval()\n",
    "\n",
    "    W_task = W_init + (W_task - W_init).detach()\n",
    "    b_task = b_init + (b_task - b_init).detach()\n",
    "    \n",
    "    queries = overfit_queries\n",
    "    outer_loss_agg, acc_agg, f1_agg = 0.0, 0.0, 0.0\n",
    "    for i, batch in enumerate(queries):\n",
    "\n",
    "        query_labels, query_input = batch\n",
    "\n",
    "        y = model_task(query_input)\n",
    "        logits = F.linear(y, W_task, b_task)\n",
    "\n",
    "        outer_loss = loss_fn(logits, query_labels)\n",
    "\n",
    "        model_task_params = [param for param in model_task.parameters() if param.requires_grad]\n",
    "        model_task_grads = torch.autograd.grad(outer_loss, model_task_params, retain_graph=True)\n",
    "\n",
    "        model_init_params = [param for param in model_init.parameters() if param.requires_grad]\n",
    "        model_init_grads = torch.autograd.grad(outer_loss, model_init_params, retain_graph=True if i != len(queries)-1 else False)\n",
    "\n",
    "        model_init_grads = model_init_grads + model_task_grads\n",
    "\n",
    "        for param, grad in zip(model_init_params, model_init_grads):\n",
    "            if param.grad != None:\n",
    "                param.grad += grad.detach()\n",
    "            else:\n",
    "                param.grad = grad.detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mets = logging_metrics(logits.detach().cpu(), query_labels.detach().cpu())\n",
    "            outer_loss_agg += outer_loss.detach().cpu().item()\n",
    "            acc_agg += mets['acc']\n",
    "            f1_agg += mets['f1']\n",
    "\n",
    "            #print(torch.norm(W_task - W_init, p=2), sum((x - y).abs().sum() for x, y in zip(model_init.state_dict().values(), model_task.state_dict().values())))\n",
    "        \n",
    "    outer_loss_agg = outer_loss_agg / len(queries)\n",
    "    acc_agg = acc_agg / len(queries)\n",
    "    f1_agg = f1_agg / len(queries)\n",
    "\n",
    "    model_init_params = [param for param in model_init.parameters() if param.requires_grad]\n",
    "    for param in model_init_params:\n",
    "        param.grad = param.grad / len(queries)\n",
    "\n",
    "    meta_optimizer.step()\n",
    "    meta_scheduler.step()\n",
    "    meta_optimizer.zero_grad()\n",
    "\n",
    "    print(\"Train | Episode {:} | Task {:<20s}, N={:} | Loss {:.4E}, Acc {:5.2f}, F1 {:5.2f} | Mem {:5.2f} GB\".format(\\\n",
    "                    episode, task, dataloader.n_classes,\n",
    "                    outer_loss_agg, acc_agg, f1_agg,\n",
    "                    psutil.Process(os.getpid()).memory_info().rss / 1024 ** 3))\n",
    "\n",
    "    writer.add_scalar('Loss/Train', outer_loss_agg, episode)\n",
    "    writer.add_scalar('Accuracy/Train', acc_agg, episode)\n",
    "    writer.add_scalar('F1/Train', f1_agg, episode)\n",
    "\n",
    "    writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = unified_emotion(\"./data/datasets/unified-dataset.jsonl\",\n",
    "                            include=['ssec'])\n",
    "dataset.prep(text_tokenizer=manual_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "No longer able to generate stratified sample.                Reshuffling and resampling.\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "task = dataset_sampler(dataset, sampling_method='sqrt')\n",
    "\n",
    "datasubset = dataset.datasets[task]['train']\n",
    "\n",
    "dataloader = StratifiedLoader(datasubset, k=16, shuffle=True, max_batch_size=config['max_support_size'], tokenizer=tokenizer, device=device, classes_subset=False)\n",
    "\n",
    "for _ in range(100):\n",
    "    support_labels, support_input, query_labels, query_input = next(dataloader)\n",
    "    print(torch.sort(torch.unique(support_labels))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1871, -0.1271, -0.2001,  ...,  0.1974, -0.2980,  0.3948],\n",
       "        [-0.1745, -0.1166, -0.1963,  ...,  0.1862, -0.2828,  0.3881],\n",
       "        [-0.2274, -0.1126, -0.2577,  ...,  0.0900, -0.3041,  0.3917],\n",
       "        ...,\n",
       "        [-0.1750, -0.1205, -0.1878,  ...,  0.2374, -0.2931,  0.3842],\n",
       "        [-0.1970, -0.1047, -0.2193,  ...,  0.1810, -0.2886,  0.3829],\n",
       "        [-0.1937, -0.1399, -0.2136,  ...,  0.1904, -0.2758,  0.3870]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "y = model_init(support_input)\n",
    "\n",
    "labs = torch.sort(torch.unique(support_labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([28, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "proto = torch.stack([torch.mean(y[support_labels==c], dim=0) for c in labs])\n",
    "W = 2 * proto\n",
    "b = - torch.norm(proto, dim=1, p=2)\n",
    "\n",
    "F.linear(y, W, b).size()"
   ]
  }
 ]
}